{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import autocast, GradScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 0.2\n",
    "DROP_OUT_P = 0.1\n",
    "num_epochs = 100\n",
    "checkpoint = \"codesage/codesage-small\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True, add_eos_token=True)\n",
    "model = AutoModel.from_pretrained(checkpoint, trust_remote_code=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "new_wte = nn.Embedding(49154, 2048)\n",
    "nn.init.normal_(new_wte.weight, mean=0, std=0.02)\n",
    "model.wte = new_wte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeSageModel(\n",
       "  (wte): Embedding(49154, 2048)\n",
       "  (wpe): Embedding(2048, 1024)\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-5): 6 x CodeSageBlock(\n",
       "      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CodeSageAttention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (residual_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): CodeSageMLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/naver/Individual/Extened/CodeSage/data.csv\")\n",
    "train_data, valid_data, train_labels, valid_labels = train_test_split(df['code'].values, df['label'].values, test_size=TEST_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bool virtio_scsi_handle_cmd_req_prepare(VirtIO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>static void term_forward_char(void)\\n\\n{\\n\\n  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>static int vaapi_build_decoder_config(VAAPIDec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>void cpu_reset (CPUMIPSState *env)\\n{\\n    mem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>static struct dirent *local_readdir(FsContext ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                code  label\n",
       "0  bool virtio_scsi_handle_cmd_req_prepare(VirtIO...      1\n",
       "1  static void term_forward_char(void)\\n\\n{\\n\\n  ...      0\n",
       "2  static int vaapi_build_decoder_config(VAAPIDec...      0\n",
       "3  void cpu_reset (CPUMIPSState *env)\\n{\\n    mem...      1\n",
       "4  static struct dirent *local_readdir(FsContext ...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True, add_eos_token=True)\n",
    "config = AutoConfig.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "config.hidden_size = 512\n",
    "model = AutoModel.from_pretrained(checkpoint, trust_remote_code=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "config.hidden_size = 512\n",
    "model = AutoModel.from_config(config,trust_remote_code=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CodeSageModel were not initialized from the model checkpoint at codesage/codesage-small and are newly initialized because the shapes did not match:\n",
      "- transformer.wte.weight: found shape torch.Size([49154, 1024]) in the checkpoint and torch.Size([49154, 512]) in the model instantiated\n",
      "- transformer.wpe.weight: found shape torch.Size([2048, 1024]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
      "- transformer.h.0.ln_1.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.0.ln_1.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.0.attn.c_attn.weight: found shape torch.Size([1024, 3072]) in the checkpoint and torch.Size([512, 1536]) in the model instantiated\n",
      "- transformer.h.0.attn.c_attn.bias: found shape torch.Size([3072]) in the checkpoint and torch.Size([1536]) in the model instantiated\n",
      "- transformer.h.0.attn.c_proj.weight: found shape torch.Size([1024, 1024]) in the checkpoint and torch.Size([512, 512]) in the model instantiated\n",
      "- transformer.h.0.attn.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.0.ln_2.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.0.ln_2.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.0.mlp.c_fc.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([512, 4096]) in the model instantiated\n",
      "- transformer.h.0.mlp.c_proj.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([4096, 512]) in the model instantiated\n",
      "- transformer.h.0.mlp.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.1.ln_1.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.1.ln_1.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.1.attn.c_attn.weight: found shape torch.Size([1024, 3072]) in the checkpoint and torch.Size([512, 1536]) in the model instantiated\n",
      "- transformer.h.1.attn.c_attn.bias: found shape torch.Size([3072]) in the checkpoint and torch.Size([1536]) in the model instantiated\n",
      "- transformer.h.1.attn.c_proj.weight: found shape torch.Size([1024, 1024]) in the checkpoint and torch.Size([512, 512]) in the model instantiated\n",
      "- transformer.h.1.attn.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.1.ln_2.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.1.ln_2.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.1.mlp.c_fc.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([512, 4096]) in the model instantiated\n",
      "- transformer.h.1.mlp.c_proj.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([4096, 512]) in the model instantiated\n",
      "- transformer.h.1.mlp.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.2.ln_1.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.2.ln_1.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.2.attn.c_attn.weight: found shape torch.Size([1024, 3072]) in the checkpoint and torch.Size([512, 1536]) in the model instantiated\n",
      "- transformer.h.2.attn.c_attn.bias: found shape torch.Size([3072]) in the checkpoint and torch.Size([1536]) in the model instantiated\n",
      "- transformer.h.2.attn.c_proj.weight: found shape torch.Size([1024, 1024]) in the checkpoint and torch.Size([512, 512]) in the model instantiated\n",
      "- transformer.h.2.attn.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.2.ln_2.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.2.ln_2.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.2.mlp.c_fc.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([512, 4096]) in the model instantiated\n",
      "- transformer.h.2.mlp.c_proj.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([4096, 512]) in the model instantiated\n",
      "- transformer.h.2.mlp.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.3.ln_1.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.3.ln_1.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.3.attn.c_attn.weight: found shape torch.Size([1024, 3072]) in the checkpoint and torch.Size([512, 1536]) in the model instantiated\n",
      "- transformer.h.3.attn.c_attn.bias: found shape torch.Size([3072]) in the checkpoint and torch.Size([1536]) in the model instantiated\n",
      "- transformer.h.3.attn.c_proj.weight: found shape torch.Size([1024, 1024]) in the checkpoint and torch.Size([512, 512]) in the model instantiated\n",
      "- transformer.h.3.attn.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.3.ln_2.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.3.ln_2.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.3.mlp.c_fc.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([512, 4096]) in the model instantiated\n",
      "- transformer.h.3.mlp.c_proj.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([4096, 512]) in the model instantiated\n",
      "- transformer.h.3.mlp.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.4.ln_1.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.4.ln_1.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.4.attn.c_attn.weight: found shape torch.Size([1024, 3072]) in the checkpoint and torch.Size([512, 1536]) in the model instantiated\n",
      "- transformer.h.4.attn.c_attn.bias: found shape torch.Size([3072]) in the checkpoint and torch.Size([1536]) in the model instantiated\n",
      "- transformer.h.4.attn.c_proj.weight: found shape torch.Size([1024, 1024]) in the checkpoint and torch.Size([512, 512]) in the model instantiated\n",
      "- transformer.h.4.attn.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.4.ln_2.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.4.ln_2.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.4.mlp.c_fc.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([512, 4096]) in the model instantiated\n",
      "- transformer.h.4.mlp.c_proj.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([4096, 512]) in the model instantiated\n",
      "- transformer.h.4.mlp.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.5.ln_1.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.5.ln_1.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.5.attn.c_attn.weight: found shape torch.Size([1024, 3072]) in the checkpoint and torch.Size([512, 1536]) in the model instantiated\n",
      "- transformer.h.5.attn.c_attn.bias: found shape torch.Size([3072]) in the checkpoint and torch.Size([1536]) in the model instantiated\n",
      "- transformer.h.5.attn.c_proj.weight: found shape torch.Size([1024, 1024]) in the checkpoint and torch.Size([512, 512]) in the model instantiated\n",
      "- transformer.h.5.attn.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.5.ln_2.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.5.ln_2.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.5.mlp.c_fc.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([512, 4096]) in the model instantiated\n",
      "- transformer.h.5.mlp.c_proj.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([4096, 512]) in the model instantiated\n",
      "- transformer.h.5.mlp.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.ln_f.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.ln_f.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(checkpoint, config=config, trust_remote_code=True, ignore_mismatched_sizes=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeSageModel(\n",
       "  (wte): Embedding(49154, 512)\n",
       "  (wpe): Embedding(2048, 512)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-5): 6 x CodeSageBlock(\n",
       "      (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): CodeSageAttention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (residual_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): CodeSageMLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model...\n",
      "Using device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CodeSageModel were not initialized from the model checkpoint at codesage/codesage-small and are newly initialized because the shapes did not match:\n",
      "- transformer.wte.weight: found shape torch.Size([49154, 1024]) in the checkpoint and torch.Size([49154, 512]) in the model instantiated\n",
      "- transformer.wpe.weight: found shape torch.Size([2048, 1024]) in the checkpoint and torch.Size([2048, 512]) in the model instantiated\n",
      "- transformer.h.0.ln_1.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.0.ln_1.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.0.attn.c_attn.weight: found shape torch.Size([1024, 3072]) in the checkpoint and torch.Size([512, 1536]) in the model instantiated\n",
      "- transformer.h.0.attn.c_attn.bias: found shape torch.Size([3072]) in the checkpoint and torch.Size([1536]) in the model instantiated\n",
      "- transformer.h.0.attn.c_proj.weight: found shape torch.Size([1024, 1024]) in the checkpoint and torch.Size([512, 512]) in the model instantiated\n",
      "- transformer.h.0.attn.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.0.ln_2.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.0.ln_2.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.0.mlp.c_fc.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([512, 4096]) in the model instantiated\n",
      "- transformer.h.0.mlp.c_proj.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([4096, 512]) in the model instantiated\n",
      "- transformer.h.0.mlp.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.1.ln_1.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.1.ln_1.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.1.attn.c_attn.weight: found shape torch.Size([1024, 3072]) in the checkpoint and torch.Size([512, 1536]) in the model instantiated\n",
      "- transformer.h.1.attn.c_attn.bias: found shape torch.Size([3072]) in the checkpoint and torch.Size([1536]) in the model instantiated\n",
      "- transformer.h.1.attn.c_proj.weight: found shape torch.Size([1024, 1024]) in the checkpoint and torch.Size([512, 512]) in the model instantiated\n",
      "- transformer.h.1.attn.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.1.ln_2.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.1.ln_2.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.1.mlp.c_fc.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([512, 4096]) in the model instantiated\n",
      "- transformer.h.1.mlp.c_proj.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([4096, 512]) in the model instantiated\n",
      "- transformer.h.1.mlp.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.2.ln_1.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.2.ln_1.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.2.attn.c_attn.weight: found shape torch.Size([1024, 3072]) in the checkpoint and torch.Size([512, 1536]) in the model instantiated\n",
      "- transformer.h.2.attn.c_attn.bias: found shape torch.Size([3072]) in the checkpoint and torch.Size([1536]) in the model instantiated\n",
      "- transformer.h.2.attn.c_proj.weight: found shape torch.Size([1024, 1024]) in the checkpoint and torch.Size([512, 512]) in the model instantiated\n",
      "- transformer.h.2.attn.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.2.ln_2.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.2.ln_2.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.2.mlp.c_fc.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([512, 4096]) in the model instantiated\n",
      "- transformer.h.2.mlp.c_proj.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([4096, 512]) in the model instantiated\n",
      "- transformer.h.2.mlp.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.3.ln_1.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.3.ln_1.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.3.attn.c_attn.weight: found shape torch.Size([1024, 3072]) in the checkpoint and torch.Size([512, 1536]) in the model instantiated\n",
      "- transformer.h.3.attn.c_attn.bias: found shape torch.Size([3072]) in the checkpoint and torch.Size([1536]) in the model instantiated\n",
      "- transformer.h.3.attn.c_proj.weight: found shape torch.Size([1024, 1024]) in the checkpoint and torch.Size([512, 512]) in the model instantiated\n",
      "- transformer.h.3.attn.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.3.ln_2.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.3.ln_2.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.3.mlp.c_fc.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([512, 4096]) in the model instantiated\n",
      "- transformer.h.3.mlp.c_proj.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([4096, 512]) in the model instantiated\n",
      "- transformer.h.3.mlp.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.4.ln_1.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.4.ln_1.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.4.attn.c_attn.weight: found shape torch.Size([1024, 3072]) in the checkpoint and torch.Size([512, 1536]) in the model instantiated\n",
      "- transformer.h.4.attn.c_attn.bias: found shape torch.Size([3072]) in the checkpoint and torch.Size([1536]) in the model instantiated\n",
      "- transformer.h.4.attn.c_proj.weight: found shape torch.Size([1024, 1024]) in the checkpoint and torch.Size([512, 512]) in the model instantiated\n",
      "- transformer.h.4.attn.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.4.ln_2.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.4.ln_2.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.4.mlp.c_fc.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([512, 4096]) in the model instantiated\n",
      "- transformer.h.4.mlp.c_proj.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([4096, 512]) in the model instantiated\n",
      "- transformer.h.4.mlp.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.5.ln_1.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.5.ln_1.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.5.attn.c_attn.weight: found shape torch.Size([1024, 3072]) in the checkpoint and torch.Size([512, 1536]) in the model instantiated\n",
      "- transformer.h.5.attn.c_attn.bias: found shape torch.Size([3072]) in the checkpoint and torch.Size([1536]) in the model instantiated\n",
      "- transformer.h.5.attn.c_proj.weight: found shape torch.Size([1024, 1024]) in the checkpoint and torch.Size([512, 512]) in the model instantiated\n",
      "- transformer.h.5.attn.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.5.ln_2.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.5.ln_2.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.h.5.mlp.c_fc.weight: found shape torch.Size([1024, 4096]) in the checkpoint and torch.Size([512, 4096]) in the model instantiated\n",
      "- transformer.h.5.mlp.c_proj.weight: found shape torch.Size([4096, 1024]) in the checkpoint and torch.Size([4096, 512]) in the model instantiated\n",
      "- transformer.h.5.mlp.c_proj.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.ln_f.weight: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "- transformer.ln_f.bias: found shape torch.Size([1024]) in the checkpoint and torch.Size([512]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training LSTM model...\")\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "DROP_OUT_P = 0.1\n",
    "num_epochs = 200\n",
    "checkpoint = \"codesage/codesage-small\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device)\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True, add_eos_token=True)\n",
    "config = AutoConfig.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "config.hidden_size = 512  \n",
    "model = AutoModel.from_pretrained(checkpoint, config=config, trust_remote_code=True, ignore_mismatched_sizes=True).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
